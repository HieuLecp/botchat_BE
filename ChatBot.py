import nltk
import numpy as np
import random
import string 
import requests
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import os
from fuzzywuzzy import process
import re 

class ChatBot():
    API_KEY = "3e95ca7740038bb5e66cf609dfaaf482"  

    def __init__(self):
        self.qa_dict = {}
        self.last_request = None  # üî• Nh·ªõ tr·∫°ng th√°i c√¢u h·ªèi g·∫ßn nh·∫•t
        self.last_city = None  # üî• Nh·ªõ t√™n th√†nh ph·ªë g·∫ßn nh·∫•t
        file_path = 'chatbot.txt'
        if not os.path.exists(file_path):
            print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {file_path}")
            exit()
        
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.read().strip().split("\n")

        current_question = None
        for line in lines:
            if line.startswith("C√¢u h·ªèi:"):
                current_question = line.replace("C√¢u h·ªèi:", "").strip().lower()
            elif line.startswith("Tr·∫£ l·ªùi:") and current_question:
                self.qa_dict[current_question] = line.replace("Tr·∫£ l·ªùi:", "").strip()
                
    def get_faq_response(self, user_input):
        """T√¨m c√¢u h·ªèi ph√π h·ª£p v·ªõi ∆∞u ti√™n t·ª´ kh√≥a v√† fuzzy matching"""
        user_input = user_input.lower().strip()

        # Danh s√°ch t·ª´ kh√≥a quan tr·ªçng li√™n k·∫øt v·ªõi c√¢u h·ªèi chu·∫©n
        keyword_mapping = {
            "h·ªßy ƒë∆°n": "T√¥i c√≥ th·ªÉ h·ªßy ƒë∆°n h√†ng sau khi ƒë√£ ƒë·∫∑t kh√¥ng?",
            "ƒë·ªïi tr·∫£": "T√¥i mu·ªën ƒë·ªïi tr·∫£ h√†ng, ph·∫£i l√†m sao?",
            "v·∫≠n chuy·ªÉn": "Ph√≠ v·∫≠n chuy·ªÉn ƒë∆∞·ª£c t√≠nh nh∆∞ th·∫ø n√†o?",
            "ki·ªÉm tra ƒë∆°n": "T√¥i c√≥ th·ªÉ ki·ªÉm tra tr·∫°ng th√°i ƒë∆°n h√†ng c·ªßa m√¨nh ·ªü ƒë√¢u?",
            "b·∫£o h√†nh": "Ch√≠nh s√°ch b·∫£o h√†nh s·∫£n ph·∫©m nh∆∞ th·∫ø n√†o?",
            "thanh to√°n": "T√¥i c√≥ th·ªÉ thanh to√°n b·∫±ng ph∆∞∆°ng th·ª©c n√†o?",
        }

        # Ki·ªÉm tra xem c√≥ t·ª´ kh√≥a quan tr·ªçng trong c√¢u h·ªèi kh√¥ng
        for keyword, correct_question in keyword_mapping.items():
            if keyword in user_input:
                return self.qa_dict.get(correct_question, "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n.")

        # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a, s·ª≠ d·ª•ng fuzzy matching
        best_match, score = process.extractOne(user_input.lower(), self.qa_dict.keys())

        if score > 80:  # Gi·∫£m ng∆∞·ª°ng xu·ªëng 70% ƒë·ªÉ nh·∫≠n di·ªán c√¢u h·ªèi thi·∫øu t·ª´
            return self.qa_dict[best_match]

        return "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ h·ªèi l·∫°i theo c√°ch kh√°c kh√¥ng?"

    @staticmethod
    def LemTokens(tokens):
        lemmer = nltk.stem.WordNetLemmatizer()
        return [lemmer.lemmatize(token) for token in tokens]

    @staticmethod
    def LemNormalize(text):
        remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
        return ChatBot.LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

    @staticmethod
    def greeting(sentence):
        GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey", "ch√†o")
        GREETING_RESPONSES = ["Hi!", "Hey!", "Hello!", "Ch√†o b·∫°n!", "Xin ch√†o!"]
        sentence = sentence.lower()
        best_match, score = process.extractOne(sentence, GREETING_INPUTS)
        for word in sentence.split():
            if score > 80:
                return random.choice(GREETING_RESPONSES)
        return None

    @staticmethod
    def get_weather(city):
        """L·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt t·ª´ OpenWeatherMap API"""
        if not city or len(city.split()) > 3:  # üî• Ch·∫∑n tr∆∞·ªùng h·ª£p nh·∫≠p c·∫£ c√¢u d√†i
            return "T√™n th√†nh ph·ªë kh√¥ng h·ª£p l·ªá. H√£y nh·∫≠p l·∫°i t√™n th√†nh ph·ªë ng·∫Øn g·ªçn."

        url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={ChatBot.API_KEY}&units=metric&lang=vi"
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()

            if "main" in data:
                temp = data['main']['temp']
                weather = data['weather'][0]['description']
                return f"üå§Ô∏è Th·ªùi ti·∫øt t·∫°i **{city.capitalize()}**: {weather}, {temp}¬∞C."
            else:
                return f"Kh√¥ng t√¨m th·∫•y th√¥ng tin th·ªùi ti·∫øt cho th√†nh ph·ªë **{city}**. H√£y ki·ªÉm tra l·∫°i t√™n!"
        
        except requests.exceptions.HTTPError as e:
            return f"L·ªói: Th√†nh ph·ªë **{city}** kh√¥ng t·ªìn t·∫°i. H√£y ki·ªÉm tra l·∫°i t√™n!"
        except requests.exceptions.RequestException as e:
            return f"L·ªói khi l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt: {str(e)}"

    def extract_city(self, user_response):
        """T√¨m t√™n th√†nh ph·ªë t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng"""
        blacklist = ["th·ªùi ti·∫øt", "·ªü", "t·∫°i", "h√¥m nay", "hi·ªán t·∫°i", "nh∆∞ th·∫ø n√†o", "?"]
        words = user_response.lower().split()

        city = " ".join([word for word in words if word not in blacklist])

        if not city:
            match = re.search(r"th·ªùi ti·∫øt.*?·ªü (.+)", user_response)
            if match:
                city = match.group(1)

        return city.strip() if len(city.split()) <= 3 else ""  # üî• Ch·ªâ nh·∫≠n t·ªëi ƒëa 3 t·ª´

    def response(self, user_response):
        """X·ª≠ l√Ω c√¢u h·ªèi b·∫±ng m√¥ h√¨nh TF-IDF"""
        self.sent_tokens.append(user_response)
        TfidfVec = TfidfVectorizer(tokenizer=lambda text: ChatBot.LemNormalize(text), stop_words='english')
        tfidf = TfidfVec.fit_transform(self.sent_tokens)

        vals = cosine_similarity(tfidf[-1], tfidf[:-1])
        idx = vals.argsort()[0][-1]
        flat = vals.flatten()
        flat.sort()
        req_tfidf = flat[-1]

        self.sent_tokens.pop()

        if req_tfidf == 0:
            return "Xin l·ªói, t√¥i kh√¥ng hi·ªÉu b·∫°n n√≥i g√¨."
        else:
            return self.sent_tokens[idx]

    def Chat_with_Bot(self, user_response):
        user_response = user_response.lower().strip()

        # üî• N·∫øu tr∆∞·ªõc ƒë√≥ h·ªèi th·ªùi ti·∫øt nh∆∞ng ch∆∞a nh·∫≠p th√†nh ph·ªë, chatbot s·∫Ω h·ªèi l·∫°i
        if self.last_request == "weather_request":
            self.last_request = None  
            self.last_city = user_response  # Nh·ªõ l·∫°i th√†nh ph·ªë
            return self.get_weather(user_response)

        # üî• N·∫øu ch·ªâ h·ªèi "th·ªùi ti·∫øt", l·∫•y th√†nh ph·ªë tr∆∞·ªõc ƒë√≥
        if user_response == "th·ªùi ti·∫øt" and self.last_city:
            return self.get_weather(self.last_city)

        # N·∫øu c√¢u ch·ª©a "th·ªùi ti·∫øt", th·ª≠ t√¨m th√†nh ph·ªë
        if self.last_request == "weather_request":
            self.last_request = None  
            self.last_city = user_response  
            return self.get_weather(user_response)

        if user_response == "th·ªùi ti·∫øt" and self.last_city:
            return self.get_weather(self.last_city)

        if "th·ªùi ti·∫øt" in user_response:
            city = self.extract_city(user_response)
            if city:
                self.last_city = city  
                return self.get_weather(city)
            else:
                self.last_request = "weather_request"  
                return "B·∫°n mu·ªën xem th·ªùi ti·∫øt ·ªü ƒë√¢u? H√£y nh·∫≠p t√™n th√†nh ph·ªë."

        # Reset tr·∫°ng th√°i n·∫øu c√¢u kh√¥ng li√™n quan ƒë·∫øn th·ªùi ti·∫øt
        self.last_request = None

        # Ch√†o h·ªèi
        greeting_res = ChatBot.greeting(user_response)
        if greeting_res:
            return greeting_res

        # X·ª≠ l√Ω c√¢u h·ªèi trong chatbot.txt
        return self.get_faq_response(user_response)
